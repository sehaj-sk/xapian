============================
Xapian QueryParser
============================

.. contents:: Table of contents
   :depth: 2
   
Introduction
============

This document is intended to provide the details of ``Xapian::QueryParser``
- the syntax and the implementation details.

The Parser is generated by `Lemon Parser Generator`_. Lemon is an LALR parser
generator for C or C++. Rather than generating a complete and working program,
it generates only a few subroutines that implements the parser.

The `Xapian QueryParser`_ contains a self-written lexer( descried below, in
`The Lexer`_) which tokenizes the query, and each time after figuring out
the type of token, calls the Lemon generated parser [to be specific, calls
the method `Parse`_ with the token detected and the corresponding information
of the token.


The Parser
===========


Functioning of Parser, The Parse Tree
++++++++++++++++++++++++++++++++++++++++

Following examples describe the functioning of the parser, the overall view
as to how are the tokens generated and how are they processed and parsed.

The bottom up parse tree corresponding to the QueryParser LR(1) grammar are
shown and described.

[**Unless mentioned explicitly, the Query objects correspond to the default
stemming option ( STEM_SOME, and hence the 'Z' prefix in some/most of them )**]


A Simple Query
---------------

Consider the following query::

	latest new watches

Here the tokens generated by the lexer are : `TERM`_ ("latest"), `GROUP_TERM`_
("new") and `GROUP_TERM`_ ("watches").

The parser then reduces the tokens in a bottom-up manner as follow::


                            
                      query		Level-7
                        |
                       expr		Level-6
                        |
                      prob_expr		Level-5
                        |
                       term		Level-4
                        |
                    compound_term	Level-3
                        |
                      group		Level-2
                      /   \
                     /     \ 
                  group     \		Level-1
                  /  \       \
                 /    \       \
                /      \       \           
             TERM  GROUP_TERM  GROUP_TERM
               |        |       |
             "latest"  "new"  "watches"

The corresponding grammar rules applied in the order of application are
as follow::

	Level 1 - group ::= TERM GROUP_TERM.
	Level 2 - group ::= group GROUP_TERM.
	Level 3 - compound_term ::= group.
	Level 4 - term ::= compound_term.
	Level 5 - prob_expr ::= term.
	Level 6 - expr ::= prob_expr.
	Level 7 - query ::= expr. 

In this case, the Query object formed is::
	
	Query((Zlatest@1 OR Znew@2 OR Zwatch@3))

Boolean Query
--------------

Consider the following query::

	xapian OR google

Here the tokens generated by the lexer are : `TERM`_ ("xapian"), `OR`_ and
`TERM`_ ("google")

The parser then reduces the tokens in a bottom-up manner as follow::

                      query		Level-6
                        |
                      expr		Level-5 
                      / |  \
                     /  |   \ 
                    /   |    \
              bool_arg  |   bool_arg	Level-4
                 |      |      |
                expr    |     expr	Level-3
                 |      |      |
            prob_expr   |    prob_expr	Level-2 
                 |      |      |
               term     |     term	Level-1
                 |      |      |
               TERM    OR     TERM
                 |      |      |
             "xapian" "OR"  "google" 
           

The corresponding grammar rules applied in the order of application are
as follow::

	Level 1 - term ::= TERM.  term ::= TERM.
	Level 2 - prob_expr ::= term.  prob_expr ::= term.
	Level 3 - expr ::= prob_expr.  expr ::= prob_expr.
	Level 4 - bool_arg ::= expr.  bool_arg ::= expr.
	Level 5 - expr ::= bool_arg OR bool_arg.
	Level 6 - query ::= expr.

In this case, the Query object formed is::
	
	Query((Zxapian@1 OR Zgoogl@2))

Similarly, other boolean operators like `AND`_, `XOR`_ etc. can be used.


Near Query
------------

Consider the following query::

	tower NEAR libery NEAR ohio

Here the tokens generated by the lexer are : `TERM`_ ("tower"), `NEAR`_ (10),
`TERM`_ ("liberty"), `NEAR`_ (10) and `TERM`_ ("ohio")

The parser then reduces the tokens in a bottom-up manner as follow::
                            
                                     query		Level-7
                                       |
                                      expr		Level-6
                                       |
                                   prob_expr		Level-5
                                       |
                                     term		Level-4
                                       |
                                compound_term		Level-3
                                       |
                                    near_expr		Level-2 
                                    /     | \
                                   /      |  \   
                                  /       |   \ 
                                 /        |    \ 
                                /         |     \
                               /          |      \           
                              /           |       \
                             /            |        \ 
                      near_expr           |         \  	Level-1
                     /    |  \            |          \   
                    /     |   \           |           \  
                   /      |    \          |            \
               TERM  NEAR(10)  TERM     NEAR(10)     TERM
               |       |         |        |            |
            "tower"  "NEAR"   "liberty"  "NEAR"      "ohio"

The corresponding grammar rules applied in the order of application are
as follow::
	
	Level 1 - near_expr ::= TERM NEAR TERM.
	Level 2 - near_expr ::= near_expr NEAR TERM.
	Level 3 - compound_term ::= near_expr.
	Level 4 - term ::= compound_term.
	Level 5 - prob_expr ::= term.
	Level 6 - expr ::= prob_expr.
	Level 7 - query ::= expr.

In this case, the Query object formed is::
	
	Query((tower@1 NEAR 12 libery@2 NEAR 12 ohio@3))

Phrased Query
---------------

Consider the following query::

	anonymous@xapian.org

Here ' @ ' and ' . ' are the `phrase generator characters`_.

Here the tokens generated by the lexer are : `TERM`_ ("anonymous"), `PHR_TERM`_
("xapian"), `PHR_TERM`_ ("org").

The parser then reduces the tokens in a bottom-up manner as follow::


                      query		Level-7
                        |
                       expr		Level-6
                        |
                      prob_expr		Level-5
                        |
                      term		Level-4 
                        |
                    compound_term	Level-3
                        |
                   phrased_term		Level-2
                      /   \
                     /     \ 
             phrased_term   \		Level-1	
                  /  \       \
                 /    \       \
                /      \       \           
             TERM   PHR_TERM  PHR_TERM
               |        |       |
       "anonymous"  "xapian"  "org"


The corresponding grammar rules applied in the order of application are
as follow::

	Level 1 - phrased_term ::= TERM PHR_TERM.
	Level 2 - phrased_term ::= phrased_term PHR_TERM.
	Level 3 - compound_term ::= phrased_term.
	Level 4 - term ::= compound_term.
	Level 5 - prob_expr ::= term.
	Level 6 - expr ::= prob_expr.
	Level 7 - query ::= expr. 

In this case, the Query object formed is::
	
	Query((anonymous@1 PHRASE 3 xapian@2 PHRASE 3 org@3))

Boolean Operator and NEAR operator
-----------------------------------

Consider the following query::

	a AND b NEAR c

Here the tokens generated by the lexer are : `TERM`_ ("a"), `AND`_ , `TERM`_
("b"), `NEAR`_ (10), `TERM`_ ("c").

This example shows the effect of precedence of NEAR being Higher than that
of boolean operators.

The parser then reduces the tokens in a bottom-up manner as follow:: 
                                 
                                 
                         query 				Level-8
                           | 
                          expr				Level-7
                        / |    \
                       /  |     \          
                      /   |      \        
                     /    |      bool_arg  		Level-6 
                    /     |           |
                   /      |           |      
                  /       |          expr		Level-5
                 /        |           |
            bool_arg      |         prob_expr		Level-4 
                |         |           | 
             expr         |           term   		Level-3
                |         |           |
           prob_expr      |          compound_term  	Level-2
                |         |                  | 
              term        |                near_expr	Level-1    
                |         |                /    |   \
                |         |               /     |    \
              TERM       AND         TERM  NEAR(10)  TERM
               |          |            |      |       |
              "a"       "AND"        "b"    NEAR     "c"


The corresponding grammar rules applied in the order of application are
as follow::

	Level 1 - term ::= TERM.		near_expr ::= TERM NEAR TERM.
	Level 2 - prob_expr ::= term.		compound_term ::= near_expr.
	Level 3 - expr ::= prob_expr.		term ::= compound_term.
	Level 4 - bool_arg ::= expr.		prob_expr ::= term.
	Level 5 - expr ::= prob_expr.
	Level 6 - bool_arg ::= expr.
	Level 7 - expr ::= bool_arg AND bool_arg.
	Level 8 - query ::= expr.

In this case, the Query object formed is::
	
	Query((Za@1 AND (b@2 NEAR 11 c@3)))



Bracketed Query and Failure of NEAR query
-------------------------------------------

Consider the following query::

	(x OR y) NEAR z

Here the tokens generated by the lexer are : `TERM`_ ("x"), `GROUP_TERM`_
("or"), `GROUP_TERM`_ ("y"), `TERM`_ ("near"), `GROUP_TERM`_ ("z").

In this example "NEAR" does not generate a `NEAR`_ query, since the boolean
query in the expressions reduces to 'expr' and there is no grammar rule at
present that supports the NEAR query with bracketed expressions.

Under such a case, the QueryParser parses the query by turning all the
flags off. Hence the tokens '(' [`BRA`_ ], ')' [`KET`_ ] , `OR`_ and `NEAR`_
are not detected.


The parser then reduces the tokens in a bottom-up manner as follow::
				     
			                 
                             query					Level-8
	                       | 
	                      expr					Level-7
	                       |  
	                    prob_expr  					Level-6
	                       |
	                      prob					Level-5
	                    /      \
	                   /        \
	                  /          \
	                 /            \
	                /              \
                  stop_term             \                               Level-4
                    |                    \     
               compound_term            stop_term                       Level-3
                    |                         |
                  group                   compound_term                 Level-2  
                  /    \                      | 
                 /      \                     |
              group      \		    group                       Level-1
              /  \        \                  /  \
             /    \        \                /    \
            /      \        \              /      \ 
         TERM   GROUP_TERM  GROUP_TERM   TERM    GROUP_TERM
 	   |       |           |           |        | 
          "x"     "OR"        "y"        "near"    "z" 

The corresponding grammar rules applied in the order of application are
as follow::

	Level 1 - group ::= TERM GROUP_TERM.		group ::= TERM GROUP_TERM.
	Level 2 - group ::= group GROUP_TERM.   	compound_term ::= group.
	Level 3 - compound_term ::= group.              stop_term ::= compound_term.
	Level 4 - stop_term ::= compound_term.
	Level 5 - prob ::= stop_term stop_term.
	Level 6 - prob_expr ::= prob.
	Level 7 -expr ::= prob_expr. 
	Level 8 - query ::= expr.

In this case, the Query object formed is::
	
	Query(((Zx@1 OR or@2 OR Zy@3) OR (near@4 OR Zz@5)))



Wildcard Query
---------------

FLAG_WILDCARD should be enabled to support the Wildcard query.

Suppose our database contains the terms "code" , "coding" , "coded" ,
"coder" , "codomain" and "codomain_new" .

Consider the following query::

	cod*

Here the token generated by the lexer is : `WILD_TERM`_ ("cod")

The parser then reduces the tokens in a bottom-up manner as follow::

                            
                query		Level-5
                  |
                 expr		Level-4
                  |
               prob_expr	Level-3	
                  |
                term		Level-2
                  |
             compound_term	Level-1
                  |
               WILD_TERM	
  		  |
	        "cod*"

The corresponding grammar rules applied in the order of application are
as follow::

	Level 1 - compound_term ::= WILD_TERM.
	Level 2 - term ::= compound_term.
	Level 3 - prob_expr ::= term.
	Level 4 - expr ::= prob_expr.
	Level 5 - query ::= expr.

In this case, the Query object formed is::

	Query((code@1 SYNONYM coded@1 SYNONYM coder@1 SYNONYM coding@1
	SYNONYM codomain@1 SYNONYM codomain_new@1))



Partial Query 
--------------

FLAG_PARTIAL should be enabled to support the partial term query.

Suppose our database contains the terms "code" , "coding" , "coded" ,
"coder" , "codomain" and "codomain_new".

Consider the following query::

	I am a cod

Here the tokens generated by the lexer is : `TERM`_ ("i"), `GROUP_TERM`_
("am"), `GROUP_TERM`_ ("a"), `PARTIAL_TERM`_ ("cod")

The parser then reduces the tokens in a bottom-up manner as follow::
				      
				      query			Level-9
					|
				      expr			Level-8
					|		
				    prob_expr			Level-7
					|
				       prob			Level-6
	                               /  \
                                      /    \
	                      stop_term     \			Level-5
                               |             \
	                   compound_term      \			Level-4
                               |               \
	                     group              \ 		Level-3
                             /   \               \
                            /     \               \   
	                 group     \              stop_term	Level-2
                         /  \       \                |
                        /    \       \          compound_term	Level-1
                       /      \       \              |
                    TERM  GROUP_TERM  GROUP_TERM   PARTIAL_TERM
                      |        |       |             |
                    "i"       "am"    "a"          "cod"

The corresponding grammar rules applied in the order of application are
as follow::


	Level 1 - compound_term ::= PARTIAL_TERM.
	Level 2 - group ::= TERM GROUP_TERM.		stop_term ::= compound_term.
	Level 3 - group ::= group GROUP_TERM.
	Level 4 - compound_term ::= group.
	Level 5 - stop_term ::= compound_term.
	Level 6 - prob ::= stop_term stop_term.
	Level 7 - prob_expr ::= prob.
	Level 8 - expr ::= prob_expr.
	Level 9 - query ::= expr. 

In this case, the Query object formed (according to the database mentioned
above) is::

	Query(((Zi@1 OR Zam@2 OR Za@3) OR ((code@4 SYNONYM coded@4 SYNONYM
	coder@4 SYNONYM coding@4 SYNONYM codomain@4 SYNONYM codomain_new@4)
	OR Zcod@4)))


Multiple Filters Query 
-----------------------

Suppose our database has the fields "site" and "description" and are prefixed
to "S" and "T" respectively::

	qp.add_boolean_prefix("site","S");
	qp.add_boolean_prefix("title","T");

Consider the following query::

	watches title:sale site:google

Here the tokens generated by the lexer are : `TERM`_ ("watches"),
`BOOLEAN_FILTER`_ ("title:sale"), `BOOLEAN_FILTER`_ ("site:google")

The parser then reduces the tokens in a bottom-up manner as follow::
                     
                        
                      query                         Level-8
                        |
                       expr                         Level-7
                        |
		     prob_expr		            Level-6
			|
		       prob			    Level-5	
		     /	    \
                    /        \
              stop_prob       \                     Level-4
		|   	       \ 	
	      prob		\		    Level-3	
	     /	  \		 \
       stop_prob   \		  \		    Level-2
	   |        \		   \   
	stop_term    \		    \  		    Level-1
           |          \              \		  
	 TERM     BOOLEAN_FILTER   BOOLEAN_FILTER   
	   |                |               |	
	"watches"	"title:sale"	"site:google"

The corresponding grammar rules applied in the order of application are
as follow::

	Level 1 - stop_term ::= TERM.
	Level 2 - stop_prob ::= stop_term.
	Level 3 - prob ::= stop_prob BOOLEAN_FILTER
	Level 4 - stop_prob ::= prob.
	Level 5 - prob ::= stop_prob BOOLEAN_FILTER
	Level 6 - prob_expr ::= prob.
	Level 7 - expr ::= prob_expr.
	Level 8 - query ::= expr. 

In this case, the Query object formed (according to the database mentioned
above) is::
	
	Query((Zwatch@1 FILTER (Sgoogle AND Tsale)))



LOVE Query
------------

Consider the following query::

	xapian +strategy

Here the tokens generated by the lexer are : `TERM`_ ("xapian"), `LOVE`_ ,
`TERM`_ ("strategy")

The parser then reduces the tokens in a bottom-up manner as follow::
              
                     
                        
	                     query		Level-6
                               |
	                      expr		Level-5
			       |
			    prob_expr		Level-4
			       |
                              prob		Level-3
                             / |  \
                            /  |   \ 
	            stop_prob  |    \		Level-2
                        |      |     \ 
	           stop_term   |    term	Level-1
                        |      |      |
                      TERM    LOVE   TERM
                        |      |      |
                    "xapian"  "+"  "strategy" 
           

The corresponding grammar rules applied in the order of application are
as follow::

	Level 1 - stop_term ::= TERM.             	term ::= TERM.
	Level 2 - stop_prob ::= stop_term.
	Level 3 - prob ::= stop_prob LOVE term.
	Level 4 - prob_expr ::= prob.
	Level 5 - expr ::= prob_expr.
	Level 6 - query ::= expr.   

In this case, the Query object formed is::
	
	Query((Zstrategi@2 AND_MAYBE Zxapian@1))

Similarly, the `HATE`_ query ("like xapian -strategy") is parsed.



An Ineffective Query
----------------------

Consider the following query::

	a OR b -c

Here the expected behaviour should be (a OR b) -c, BUT the present grammar
parses it as a OR ( b -c )

This is a present bug ( `ticket #521`_ )

Here the tokens generated by the lexer are : `TERM`_ ("a"), `OR`_ , `TERM`_
("b"), `HATE`_ , `TERM`_ ("c")

The parser then reduces the tokens in a bottom-up manner as follow::
                      
                               query				Level-8
                                |
                               expr				Level-7
                              /|   \
                     	     / |    \ 
			    /  |     \		                     
			   /   |      bool_arg			Level-6
		          /    |          |
			 /     |         expr			Level-5
			/      |	    |
		   bool_arg    |	  prob_expr		Level-4
		       |       |	      |
		     expr      |             prob		Level-3
		       |       |            / |  \
		       |       |           /  |   \ 
		     prob_expr |  stop_prob   |    \		Level-2
		       |       |      |       |     \
		     term      |   stop_term  |    term		Level-1
		       |       |      |       |      |
		     TERM      OR    TERM   HATE   TERM
		       |       |      |      |      |
	              "a"     "OR"   "b"    "-"    "c"                         

The corresponding grammar rules applied in the order of application are
as follow::

	Level 1 - term ::= TERM.	stop_term ::= TERM.	term ::= TERM.
	Level 2 - prob_expr ::= term.	stop_prob ::= stop_term.
	Level 3 - expr ::= prob_expr.	prob ::= stop_prob HATE term.
	Level 4 - bool_arg ::= expr.	prob_expr ::= prob.
	Level 5 - expr ::= prob_expr.
	Level 6 - bool_arg ::= expr.
	Level 7 - expr ::= bool_arg OR bool_arg.
	Level 8 - query ::= expr.  

In this case, the Query object formed is::
	
	Query((Za@1 OR (Zb@2 AND_NOT Zc@3)))
	



Grammar Rules
++++++++++++++

Following are the grammar rules of QueryParser , listed together in the order::

	0.  query ::= expr.

	1.  query ::= .

	2.  expr ::= prob_expr.

	3.  expr ::= bool_arg AND bool_arg.

	4.  expr ::= bool_arg NOT bool_arg.

	5.  expr ::= bool_arg AND NOT bool_arg.

	6.  expr ::= bool_arg AND HATE_AFTER_AND bool_arg.

	7.  expr ::= bool_arg OR bool_arg.

	8.  expr ::= bool_arg XOR bool_arg.

	9.  bool_arg ::= expr.

	10. bool_arg ::= . 

	11. prob_expr ::= prob.

	12. prob_expr ::= term.

	13. prob ::= RANGE.

	14. prob ::= stop_prob RANGE.

	15. prob ::= stop_term stop_term.

	16. prob ::= prob stop_term.

	17. prob ::= LOVE term.

	18. prob ::= stop_prob LOVE term.

	19. prob ::= HATE term.

	20. prob ::= stop_prob HATE term.

	21. prob ::= HATE BOOLEAN_FILTER.

	22. prob ::= stop_prob HATE BOOLEAN_FILTER.

	23. prob ::= BOOLEAN_FILTER.

	24. prob ::= stop_prob BOOLEAN_FILTER.

	25. prob ::= LOVE BOOLEAN_FILTER.

	26. prob ::= stop_prob LOVE BOOLEAN_FILTER.

	27. stop_prob ::= prob.

	28. stop_prob ::= stop_term.

	29. stop_term ::= TERM.

	30. stop_term ::= compound_term.

	31. term ::= TERM.

	32. term ::= compound_term.

	33. compound_term ::= WILD_TERM.

	34. compound_term ::= PARTIAL_TERM.

	35. compound_term ::= QUOTE phrase QUOTE.

	36. compound_term ::= phrased_term.

	37. compound_term ::= group.

	38. compound_term ::= near_expr.

	39. compound_term ::= adj_expr.

	40. compound_term ::= BRA expr KET.

	41. compound_term ::= SYNONYM TERM.

	42. compound_term ::= CJKTERM.

	43. phrase ::= TERM.

	44. phrase ::= CJKTERM.

	45. phrase ::= phrase TERM.

	46. phrase ::= phrase CJKTERM.

	47. phrased_term ::= TERM PHR_TERM.

	48. phrased_term ::= phrased_term PHR_TERM.

	49. group ::= TERM GROUP_TERM.

	50. group ::= group GROUP_TERM.

	51. group ::= group EMPTY_GROUP_OK.

	52. near_expr ::= TERM NEAR TERM.

	53. near_expr ::= near_expr NEAR TERM.

	54. adj_expr ::= TERM ADJ TERM.

	55. adj_expr ::= adj_expr ADJ TERM.



TERMINALS
++++++++++

In Lemon a terminal symbol (token) is any string of alphanumeric and underscore
characters that begins with an upper case letter.

In Lemon,ALL Terminals must have the same type (as mentioned above, in
Xapian, each terminal has the type `Class Term`_ thus all the information
corresponding to a token is stored in the corresponding Term object) but
Non-Terminals can have their own (different) types/values.


The QueryParser grammar has the following 23 TERMINALS :

_`ERROR`
---------
Used to represent an error in the query i.e. a malformed query.

For Example, the Boolean Operators (AND, OR etc. ) require the syntax to be
of type ``<expression> Operator <expression>``, if it is not so, then that
corresponds to `ERROR`_

_`OR`
------

This matches the documents which are matched by either of the subqueries.

Example Query::

    A OR B

Which Documents are Passed ?
    Passes documents which match query A or B (or both)

How is the Weight of the Documents Adjusted ?
    Passes documents with the sum of weights from A and B

_`XOR`
-------

This matches the documents which are matched by one or the other subquery,
but not both.

Example Query::

    A XOR B

Which Documents are Passed ?
    Passes documents which match query A or B (but not both)

How is the Weight of the Documents Adjusted ?
    Passes documents with the weight from A or B, depending which one
    it matches.

_`AND`
-------

This matches the documents which are matched by both the subqueries.

Example Query::

    A AND B

Which Documents are Passed ?
    Passes documents which match both query A and B

How is the Weight of the Documents Adjusted ?
    Passes documents with the sum of weights from A and B

_`NOT`
-------

This matches the documents that are matched only by first subquery and not
the second subquery.

Example Query::

    A NOT B

Another Equivalent Query::

    A AND NOT B

Which Documents are Passed ?
    Passes documents which match query A but not B

How is the Weight of the Documents Adjusted ?
    Passes documents with the weight from A only

If FLAG_PURE_NOT is enabled, then queries like ``NOT subquery`` can be
used. This matches the documents that are not matched
by the subquery

_`NEAR`
--------

This matches documents containing the both the words - word1 and word2
such that they are within 10 words of each other. The default value of NEAR
operator is 10.

Example Query::

    A NEAR B

Which Documents are Passed ?
    Passes documents which matches A within 10 words(if default value i.e. 10
    is used) of B.

How is the Weight of the Documents Adjusted ?
    Passes the matched documents with the weight of A+B

We can change the default value by using NEAR/n which corresponds to the token
``NEAR(N)``.

Example Query::

    word1 NEAR/5 word2

This matches documents containing the both the words - word1 and word2 such
that they are within 5 words of each other.

_`ADJ`
-------

ADJ is similar to NEAR with the difference that it matches ONLY IF the words
specified in the query with ADJ operator appear in **same order** as
mentioned in the query.

For Example, if I have a document containing::

    xapian parser provides a new stemming strategy

Then all the following three queries will match this document::

    xapian NEAR strategy
    strategy NEAR xapian
    xapian ADJ strategy

But the query::

    strategy ADJ xapian

will NOT MATCH this document.

Similar to NEAR the default value of ADJ is 10. It can be changed to n by
a query like following::

    word1 ADJ/n word2

The ADJ/n corresponds to ``ADJ(n)`` token.


_`LOVE`
--------

If ``FLAG_LOVEHATE`` is enabled then '``+``' after a whitespace or an open
bracket corresponds to the token ``LOVE`` but
with following conditions:

 - If "+" is followed by space, then it is ignored.
    For Example, in the following case token LOVE is detected::

        Query: xapian +strategy
        Query object formed: strategy@2 AND_MAYBE xapian@1

    But in this case::

        Query: xapian + strategy
        Query object formed: xapian@1 OR strategy@2

    the "+" is followed by a whitespace and thus
    not detected as a LOVE token.

 - A Postfix "+" (such as in google+) is not treated as a LOVE token.
    Under such case, the character "+" is regarded as a part of the term
    only by the lexer.

    For example in the following case "+" is treated as the part of the term
    google only and not as a separate token::

        Query: profile google+
        Query object formed: profile@1 OR google+@2

 - Ignored if present at the end of the query.

Example query::

    xapian +strategy

The above query returns the query following query object::

    "strategy@2 AND_MAYBE xapian@1".


Consider::

    A AND_MAYBE B

Which Documents are Passed?
    Passes documents which matches A or (A and B).

How is the Weight of Documents Adjusted?
    Documents which match A and B are passed, with weight of A+B

    Documents which match A only are passed, with weight of A

    Documents which match B only are not passed


_`HATE`
--------

If ``FLAG_LOVEHATE`` is enabled then "``-``" after a whitespace or an open
bracket corresponds to the token HATE but with
the following conditions:

 - If "-" is followed by space, then it is ignored.
    For Example, in the following case, the token HATE is detected::

        Query: xapian -strategy
        Query object formed: xapian@1 AND_NOT strategy@2"

    But in this case::

        Query: xapian - strategy
        Query object formed: xapian@1 OR strategy@2

    the "-" is followed by a whitespace and thus not detected as a HATE token.

 - A Postfix - (such as in xapian-) is not treated as a HATE token.
    Under such case, the character "-" is simply ignored by the lexer and
    is not regarded as a part of the term.

    For example, In the following case::

        Query: xapian- core
        Query object formed: xapian@1 OR core@2

    "-" is simply ignored and is not treated as the part of the term xapian
    or as a separate token.

 - Ignored if present at the end of the query.

Example query::

    xapian -strategy

The above query returns the following query object::

    xapian@1 AND_NOT strategy@2


Consider::

    A AND_NOT B

Which Documents are Passed?
    Passes the documents which match query A but not B.

How is the Weight of Documents Adjusted?
    Passes documents with the weight from A only.


_`HATE_AFTER_AND`
-------------------

If ``FLAG_LOVEHATE`` is enabled then "``-``" after AND operator corresponds
to the token HATE_AFTER_AND.


_`SYNONYM`
-----------

If ``FLAG_SYNONYM`` is enabled then "``~``" after a whitespace, +, -, or an
open bracket corresponds to the token SYNONYM
but with the following conditions:

 - It is ignored if not followed by a word character.
    For example, Consider the database in which we have specified "``happy``"
    and "``cheerful``" as synonyms.

    Then in the following case, the query object will be formed so since
    here the token SYNONYM has been detected::

        Query: ~happy
        Query object formed: happy@1 SYNONYM cheerful@1

    But in this case::

        Query: ~ happy
        Query object formed: happy@1

    the "-" is followed by a whitespace and thus not detected as a SYNONYM
    token.

 - Ignored if present at the end of the query.


Example query

**NOTE**: we must call `set_database()`_ for this to work. Also we need
to add the synonyms to the document. This can be done as follow::

    Xapian::WritableDatabase db(@param);
    db.add_synonym("happy", "cheerful");
    Xapian::QueryParser qp;
    qp.set_database(db);

Now if we give a query::

    ~happy

then the Query object returned is::

    happy@1 SYNONYM cheerful@1


SYNONYM is identical to OR except for the weightings returned.

Which Documents are Passed? :
    Passes documents that match at least one of the queries.

How is the Weight of Documents Adjusted?
    Documents are weighted as if all the sub-queries are are instances of
    the same term, so multiple matching terms increase the wdf value used,
    and the term frequency is based on the number of documents which will
    match an OR of all the subqueries.


_`TERM`
--------

TERM is a query term, including prefix (if any).

_`GROUP_TERM`
---------------

GROUP_TERM is a query term which follows a TERM or another GROUP_TERM and
is only separated by whitespace characters.


_`PHR_TERM`
-------------

PHR_TERM is a query term which follows a TERM or another PHR_TERM and is
separated only by one or more phrase generator
characters (hyphen and apostrophe are common examples).

_`Phrase generator characters` (tested via `is_phrase_generator()`_ ) are the
characters that generate a phrase search.


Currently Xapian supports the following characters as phrase generator::

    '.' , '-' , '/' , ':' , '\\' , '@'

The phrase operator allows for searching for a specific phrase and returns
only matches where all terms appear in th document, in the correct order,
giving a weight of the sum of each term.

For example, The query object::

    a@1 PHRASE 3 b@2 PHRASE 3 c@3

matches the documents which match A followed by B followed by C and gives
them a weight of A+B+C.


.. _above:

*Examples of phrase search* :

 - The following case generates phrase query since '.' is a phrase generator::

       Query: xapian.org
       Query object formed: xapian@1 PHRASE 2 org@2

 - The following case generates a phrase query since the words of the query
 are enclosed in quotes::

       Query: "A B C"
       Query object formed: a@1 PHRASE 3 b@2 PHRASE 3 c@3

 - The following case also generates a phrase query since '/' is a phrase
 generator::

       Query: /home/user/xapian/xapian-core
       Query object formed: home@1 PHRASE 5 user@2 PHRASE 5 xapian@3 PHRASE
       5 xapian@4 PHRASE 5 core@5


Phrase search also plays an important role with the filters.

For Example suppose we add the filter (non-boolean) for field "``title``"
by mapping it to prefix "``T``" (by doing
``qp.add_prefix("title","T")``),

Then in the following case, the whole title is treated as a single entity
since the words are connected by ``OP_PHRASE`` and also that all words are
prefixed by "T"::

    Query: title:"Harry Potter and the Chamber of Secrets"
    Query object returned: Tharry@1 PHRASE 7 Tpotter@2 PHRASE 7 Tand@3 PHRASE
    7 Tthe@4 PHRASE 7 Tchamber@5 PHRASE 7 Tof@6 PHRASE 7 Tsecrets``" i.e.

Whereas in this case::

    Query: title:Harry Potter and the Chamber of Secrets
    Query object returned: Tharry@1 OR potter@2 OR and@3 OR the@4 OR chamber@5
    OR of@6 OR secrets@7

the whole title is not treated as a single entity since the words are
connected by OP_OR and also all words are not prefixed by "T".

**Note**: For the phrase searches, FLAG_PHRASE should be enabled. (By default
it is enabled)



Consider::

    A OP_PHRASE B OP_PHRASE C

Which Documents are Passed? :
    Passes documents that match A followed by B followed by C.

How is the Weight of Documents Adjusted?
    Matched documents are are given a weight of A+B+C.


_`WILD_TERM`
-------------

WILD_TERM is like a TERM, but has a trailing wildcard which needs to be
expanded. It is used to match any number of trailing characters within a term
(Right Truncation).

**Note**: Like in the case of synonyms, for the wildcard expansion we must
call `set_database()`_ . Also the wildcard expansion works ONLY IF
``FLAG_WILDCARD`` is enabled. (By default, it is
not enabled).

You can limit the number of terms a wildcard will expand to by calling
`Xapian::QueryParser::set_max_wildcard_expansion()`_

If a wildcard expands to more terms than that number, an exception will be
thrown. The exception may be thrown by the
QueryParser, or later when Enquire handles the query. The default is not to
limit the expansion.

*Example of wildcard query* :

Consider our database contains the terms::

    "code" , "coding" , "coded" , "coder" , "codomain" , "codomain_new"

Then the query::

    cod*

will return the following Query object::

    code@1 SYNONYM coded@1 SYNONYM coder@1 SYNONYM coding@1 SYNONYM codomain@1
    SYNONYM codomain_new@1



_`PARTIAL_TERM`
-----------------

PARTIAL_TERM is like a TERM, but it's at the end of the query string and
we're doing "search as you type". It refers to
the final term of a partial match query, with no following characters and
is thus treated as a wildcard, thus expands to
something like WILD_TERM.

Partial matching causes the parser to treat the query as a "*partially
entered*" search.


This will automatically treat the final word as a wildcard match, unless it
is followed by whitespace, to produce more
stable results from interactive searches.

**Note** : ``FLAG_PARTIAL`` should be enables to support the partial term query

*Example of partial term query* :

Consider the same database as used above in wildcard query. Our database
contains the terms::

    "code" , "coding" , "coded" , "coder" , "codomain" , "codomain_new"

Then the query::

    I am a cod

will treat the last word of the query ("``cod``") as wildcard term and thus
return the following Query object::

    (i@1 OR am@2 OR a@3) OR ((code@4 SYNONYM coded@4 SYNONYM coder@4 SYNONYM
    coding@4 SYNONYM codomain@4 SYNONYM codomain_new@4) OR cod@4)

The problem with this kind of search is that the last word in a partially
entered query often has no semantic relation to the completed word. For
example, a search for "``dynamic cat``" would return a quite different
set of results to a search for "``dynamic categorisation``". This results
in the set of results displayed flicking rapidly as each new character is
entered. A much smoother result can be obtained if the final word is treated
as having an implicit terminating wildcard, so that it matches all words
starting with the entered characters - thus, as each letter is entered,
the set of results displayed narrows down to the desired subject.

A similar effect could be obtained simply by enabling the wildcard matching
option, and appending a "*" character to each query string. However,
this would be confused by searches which ended with punctuation or other
characters.



_`BOOLEAN_FILTER`
-------------------

BOOLEAN_FILTER is a query term with a prefix registered using
`add_boolean_prefix()`_

It's added to the query using an OP_FILTER operator,(or OP_AND_NOT if it's
negated) for example, ``site:xapian.org`` or ``-site:xapian.org``.

For example, Suppose in our database, we make the field "``site``" a Boolean
filter::

    qp.add_boolean_prefix("site","S")

Now consider the following query::

    watches site:google

The above query will return the following Query object::

    watches@1 FILTER Sgoogle

The corresponding search will return all the documents from site google ONLY
(and not any other site since we made "site" a boolean filter) which have
the term "watches" in it.

The operator ``OP_FILTER`` (corresponding to FILTER ) is used (and not OP_OR)
since the type of prefix is BOOLEAN_EXCLUSIVE.

If there are boolean filters for different prefixes, they will be combined
with the Xapian::Query::OP_AND operator.

For example, Consider the same database with the fields "site" and
"description".

Let us make both of these boolean filters with DIFFERENT prefixes::

    qp.add_boolean_prefix("site","S");
    qp.add_boolean_prefix("title","T");

Now consider the following query::

    watches site:google title:sale

The above query will return the following Query object::

    watches@1 FILTER (Sgoogle AND Tsale).

If multiple boolean filters are specified in a query for the same prefix,
they will be combined with the Xapian::Query::OP_OR
operator.

For example, Consider the same database with the fields "``site``" and
"``description``".

Let us make both of these boolean filters with SAME prefixes::

    qp.add_boolean_prefix("site","S");
    qp.add_boolean_prefix("title","S");

Now consider the following query::

    watches site:google title:sale

The above query will return the following Query object::

    watches@1 FILTER (Sgoogle OR Ssale)

It is also possible to make multiple boolean filters specified for SAME
prefixes to be combined with OP_AND (and not with
OP_OR as is in the case above).

This corresponds to the case where the document can have multiple terms with
this prefix, so multiple filters should be
combined with OP_AND, like happens with filters with different prefixes.

For example, Consider the same database with the fields "site" and
"description".

Let us make both of these boolean filters with SAME prefixes::

    qp.add_boolean_prefix("site","S");
    qp.add_boolean_prefix("title","S",false);

Now consider the following query::

    watches site:google title:sale

The above query will return the following Query object::

    watches@1 FILTER (Sgoogle AND Ssale)



_`RANGE`
---------

This token corresponds to a Range search.

The QueryParser supports range searches on document values, matching documents
which have values within a given range. There are several types of range
processors available.

To use a range, additional programming is required to tell the QueryParser
what format a range is specified in and which value is to be searched for
matches within that range. This then gives rise
to the ability to specify ranges as:

$10..50 5..10kg 01/01/1970..01/03/1970 size:3..7

When date ranges are configured (as a DateValueRangeProcessor), you can
configure which format dates are to be interpreted as (i.e. month-day-year)
or otherwise.


_`QUOTE`
----------

Characters ' ``"`` ' , left curly double quote(0x201c) and the right curly
double quote(0x201d) match to the token QUOTE.

An unmatched " at the end of the query is ignored to avoid generating an
empty pair of QUOTEs which will cause a parse error.

The grammar rule corresponding to the phrased searched is : **QUOTE phrase(P)
QUOTE**. Examples of phrased search were
given above_ .


_`BRA`
--------

Character '``(``' after a whitespace, bracket , '+' or '-' matches to the
token BRA with the following conditions:

 - It is ignored if present at the end of the query.
 - It is ignored if the case corresponds to empty ().

The grammar rule corresponding to the bracketed expression is

    compound_term ::= BRA expr KET


_`KET`
--------

Character '``)``' represents the token KET. It represents the end of a
bracketed expression.

The grammar rule corresponding to the bracketed expression is::

    compound_term ::= BRA expr KET


_`CJKTERM`
------------

It corresponds to the case if CJK n-gram code is being used i.e. if
`CJK::is_cjk_enabled()`_ is true and `CJK::codepoint_is_cjk(*itertor)`_
returns true.


_`EMPTY_GROUP_OK`
-------------------

This token corresponds to the end of group (a non-terminal), where group
refers to a group of terms separated only by whitespace - candidates for
multi-term synonyms

The corresponding grammar rule is::

    group ::= group EMPTY_GROUP_OK



The Lexer
==========

QueryParser has a self written lexer which iterates through the input query,
determines the Tokens and calls the parser ( to be precise, calls the method
`Parse`_ ) each time a new Token is determined, along with the information
of that Token.

The lexer uses the enum mode to keep track of the present state and the
information of the past Token(s).::

    enum {
	DEFAULT, IN_QUOTES, IN_PREFIXED_QUOTES, IN_PHRASED_TERM, IN_GROUP,
	IN_GROUP2, EXPLICIT_SYNONYM
    } mode = DEFAULT;

The default value of mode is DEFAULT.

Following is the information regarding each of them :


DEFAULT
++++++++
This is the default value of mode.


IN_QUOTES
++++++++++
If ' ``"`` ' character detected along with the conditions that are required
for Quotes (as mentioned above in `QUOTE`_ ), then the mode is set to this
one and parser is called with parameters as::


     Parse(pParser, QUOTE, NULL, &state);


IN_PREFIXED_QUOTES
++++++++++++++++++++
Same as `IN_QUOTES`_, and the method `Parse`_ is called with same parameters.

The only difference is that it corresponds to a case like

    subject:"space flight"

where "``subject``" corresponds to a filter.


IN_PHRASED_TERM
++++++++++++++++
The character is tested for phrase generator (as mentioned above in `PHR_TERM`_
), and if it is, then the mode is set to this one and the parser is called
with the parameters as::

    Parse(pParser, PHR_TERM, term_obj, &state);


IN_GROUP
+++++++++
If the we have a term, and we detect another term such that they are separated
only via whitespace, then this mode is set.


IN_GROUP2
++++++++++
This is same as `IN_GROUP`_ with the difference that this corresponds to
the case when we have more than two terms separated via whitespace.


EXPLICIT_SYNONM
++++++++++++++++
If ' ``~`` ' character is detected along with the conditions that are
required for Synonyms (as described above in `SYNONYM`_), then the mode is
set to this one and the parser is called with parameters as::


    Parse(pParser, SYNONYM, NULL, &state);




Bibliography
=============

_`Lemon Parser Generator` <http://www.hwaci.com/sw/lemon/>

_`Parse`
<http://xapian.org/docs/sourcedoc/html/queryparser__internal_8cc.html#ee7aae42b4ccbfa6af14f369ccafbc69>

_`ticket #521` <http://trac.xapian.org/ticket/521>

_`Class Term` <http://xapian.org/docs/sourcedoc/html/classTerm.html>

_`is_phrase_generator()`
<http://xapian.org/docs/sourcedoc/html/queryparser__internal_8cc.html#ab60021d249d420797bf71899944a5d3>

_`set_database()`
<http://xapian.org/docs/sourcedoc/html/classXapian_1_1QueryParser.html#010f2b63522f063aa3b5f5645479d9e9>

_`Xapian::QueryParser::set_max_wildcard_expansion()`
<http://xapian.org/docs/sourcedoc/html/classXapian_1_1QueryParser.html#8e2bcb09952fbb2b713ef61e8eb6f638>`

_`add_boolean_prefix()`
<http://xapian.org/docs/sourcedoc/html/classXapian_1_1QueryParser.html#411cc8253c599b7d877749b8e814ee76>

_`CJK::is_cjk_enabled()`
<http://xapian.org/docs/sourcedoc/html/namespaceCJK.html#6d76ede0fd2a9ad3a12532d63c05caee>

_`CJK::codepoint_is_cjk(*itertor)`
<http://xapian.org/docs/sourcedoc/html/namespaceCJK.html#efab5934f6a82a989b994fad5068670d>

