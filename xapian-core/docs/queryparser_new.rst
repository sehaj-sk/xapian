============================
Xapian QueryParser
============================

.. contents:: Table of contents
   :depth: 2
   
Introduction
============

This document is intended to provide the details of ``Xapian::QueryParser`` - the syntax and the implementation details.

The Parser is generated by `Lemon Parser Generator <http://www.hwaci.com/sw/lemon/>`_. Lemon is an LALR parser generator for
C or C++. Rather than generating a complete and working program, it generates only a few subroutines that implements the parser.

The `Xapian QueryParser`_ contains a self-written lexer( descried below, in `The Lexer`_) which tokenizes the query, and
each time after figuring out the type of token, calls the Lemon generated parser [to be specific, calls the method `static
void Parse( yyParser * , int, Term * , State * )`_ with the token detected and the corresponding information of the token.



Lemon Generated Subroutines
===========================

The prototype and description of the four subroutines that are generated in `Xapian QueryParser`_ using Lemon are :


static yyParser * ParseAlloc()
-------------------------------


static void ParseFree( yyParser * )
------------------------------------


static void Parse( yyParser * , int, Term * , State * )
-------------------------------------------------------

This is the main parser function. It is called each time a token is generated by the lexer.

 - The *first argument* is the pointer returned by `static yyParser * ParseAlloc()`_.
 - The *second argument* is the integer that tells the parser the type of the token to be parsed. There is one token for each TERMINAL symbol specified in the grammar.The TERMINAL symbols are mapped to appropriate integer values.
 - The *third argument* is the value of the given token. Xapian uses a `Class Term <http://xapian.org/docs/sourcedoc/html/classTerm.html>`_ to store all the corresponding information related to the token. This class is used to pass the information about a token from lexer to parser.
 - The *fourth argument* is an instance of the `Class State <http://xapian.org/docs/sourcedoc/html/classState.html>`_ . It is the Parser State that is shared between the lexer and the parser.
    Lemon provides the feature of fourth parameter that can be of any type chosen by the programmer.The parser doesn't do
    anything with this argument except to pass it through to action routines. This is a convenient mechanism for passing
    state information down to the action routines without having to use global variables.



static void yy_parse_failed( yyParser * )
-----------------------------------------

This method is specified under ``%syntax_error`` directive provided by Lemon.

When a Lemon-generated parser encounters a syntax error, it first invokes the code specified by the ``%syntax_error``
directive [ in our case, `static void yy_parse_failed( yyParser * )`_ ] . It then enters its error recovery strategy. The
error recovery strategy is to begin popping the parser's stack until it enters a state where it is permitted to shift a
special non-terminal symbol named ``error``. It then shifts this non-terminal and continues parsing. But the ``%syntax_error``
routine will not be called again until at least three new tokens have been successfully shifted.

If the parser pops its stack until the stack is empty, and it still is unable to shift the error symbol, then the
``%parse_failed`` routine is invoked and the parser resets itself to its start state, ready to begin parsing a new file.






The Parser Grammar
===================

In Lemon,ALL Terminals must have the same type (as mentioned above, in Xapian, each terminal has the type `Class Term
<http://xapian.org/docs/sourcedoc/html/classTerm.html>`_ thus all the information corresponding to a token is stored in
the corresponding Term object) but Non-Terminals can have their own (different) types/values.



TERMINALS
----------

In Lemon a terminal symbol (token) is any string of alphanumeric and underscore characters that begins with an upper case letter. 

The QueryParser grammar has the following 23 TERMINALS : 

ERROR
~~~~~~

OR
~~~

Example Query : ``subquery1 OR subquery2``. 

This matches the documents which are matched by either of the subqueries.

Details of Xapian::Query::OP_OR
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Consider ``A OP_OR B``

Which Documents are Passed ?
 Passes documents which match query A or B (or both)
How is the Weight of the Documents Adjusted ?
 Passes documents with the sum of weights from A and B

XOR
~~~~~~

Example Query : ``subquery1 XOR subquery2``. 

This matches the documents which are matched by one or the other subquery, but not both.

Details of Xapian::Query::OP_XOR
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Consider ``A OP_XOR B``

Which Documents are Passed ?
 Passes documents which match query A or B (but not both)
How is the Weight of the Documents Adjusted ?
 Passes documents with the weight from A or B, depending which one it matches.

AND
~~~~~~

Example Query : ``subquery1 OR subquery2``. 

This matches the documents which are matched by both the subqueries.

Details of Xapian::Query::OP_AND
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Consider ``A OP_AND B``

Which Documents are Passed ?
 Passes documents which match both query A and B
How is the Weight of the Documents Adjusted ?
 Passes documents with the sum of weights from A and B

NOT
~~~~~~

Example Query : ``subquery1 NOT subquery2``.

Another Example Query :  ``subquery1 AND NOT subquery2``.

This matches the documents that are matched only by first subquery and not the second subquery. 

If FLAG_PURE_NOT is enabled, then queries like ``NOT subquery`` can be used. This matches the documents that are not matched
by the subquery.


Details of Xapian::Query::OP_AND_NOT
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Consider ``A OP_AND_NOT B``

Which Documents are Passed ?
 Passes documents which match query A but not B
How is the Weight of the Documents Adjusted ?
 Passes documents with the weight from A only


NEAR
~~~~~~


Example Query : ``word1 NEAR word2``. 

This matches documents containing the both the words - word1 and word2 such that they are within 10 words of each other. The
default value of NEAR operator is 10.

We can change the default value by using NEAR/n which corresponds to the token ``NEAR(N)``.

Example Query : ``word1 NEAR/5 word2``.

This matches documents containing the both the words - word1 and word2 such that they are within 5 words of each other.


Details of Xapian::Query::OP_NEAR
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Consider ``A OP_NEAR B``

Which Documents are Passed ?
 Passes documents which matches A within 10 words(if default value i.e. 10 is used) of B.
How is the Weight of the Documents Adjusted ?
 Passes the matched documents with the weight of A+B

ADJ
~~~~

ADJ is similar to NEAR with the difference that it matches ONLY IF the words specified in the query with ADJ operator appear
in ***same order*** as mentioned in the query.

For Example, if I have a document containing "``xapian parser provides a new stemming strategy``".

Then both the queries "``xapian NEAR strategy``" and "``strategy NEAR xapian``" will match this document. Also "``xapian
ADJ strategy``" will match this document but "``strategy ADJ xapian``" will NOT MATCH this document.

Similar to NEAR the default value of ADJ is 10. It can be changed to n by a query like following: ``word1 ADJ/n word2``. The
ADJ/n corresponds to ``ADJ(n)`` token.



LOVE
~~~~

If ``FLAG_LOVEHATE`` is enabled then "``+``" after a whitespace or an open bracket corresponds to the token ``LOVE`` but
with following conditions:

 - If "+" is followed by space, then it is ignored.
    For Example, the query "``xapian +strategy``" returns the Query object "``strategy@2 AND_MAYBE xapian@1``" Since in
    this case the token LOVE is detected.

    But the query "``xapian + strategy``" returns the Query object "``xapian@1 OR strategy@2``" because here the "+" is
    followed by a whitespace and thus not detected as a LOVE token.

 - A Postfix "+" (such as in google+) is not treated as a LOVE token.
    Under such case, the character "+" is regarded as a part of the term only by the lexer.

    E.g. The query "``profile google+``" returns the query object "``profile@1 OR google+@2``" i.e. "+" is treated as the
    part of the term google only and not as a separate token.
 - Ignored if present at the end of the query.

*Example query which involve LOVE token* : As mentioned above, the query "xapian +strategy" returns the query object
"strategy@2 AND_MAYBE xapian@1".



Details of Xapian::Query::OP_AND_MAYBE
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Consider ``A OP_AND_MAYBE B``
 
Which Documents are Passed?
 Passes documents which matches A or (A and B).
How is the Weight of Documents Adjusted?
 Documents which match A and B are passed, with weight of A+B

 Documents which match A only are passed, with weight of A

 Documents which match B only are not passed


HATE
~~~~
If ``FLAG_LOVEHATE`` is enabled then "``-``" after a whitespace or an open bracket corresponds to the token HATE but with
the following conditions:

 - If "-" is followed by space, then it is ignored.
    For Example, The query "``xapian -strategy``" returns the Query object "xapian@1 AND_NOT strategy@2" since in this case
    the token HATE is detected.

    But the query "``xapian - strategy``" returns the Query object "``xapian@1 OR strategy@2``" because here the "-" is
    followed by a whitespace and thus not detected as a HATE token.

 - A Postfix - (such as in xapian-) is not treated as a HATE token.
    Under such case, the character "-" is simply ignored by the lexer and is not regarded as a part of the term.

    E.g. The query "``xapian- core``" returns the query object "``xapian@1 OR core@2``" i.e. "-" is simply ignored and is
    not treated as the part of the term xapian or as a separate token.

 - Ignored if present at the end of the query.

*Example query which involve HATE token* : As mentioned above, the query "``xapian -strategy``" returns the query object
"``xapian@1 AND_NOT strategy@2``".



Details of Xapian::Query::OP_AND_NOT
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Consider A OP_AND_NOT B 
 
Which Documents are Passed? 
 Passes the documents which match query A but not B.
How is the Weight of Documents Adjusted?
 Passes documents with the weight from A only.


HATE_AFTER_AND
~~~~~~~~~~~~~~~
If ``FLAG_LOVEHATE`` is enabled then "``-``" after AND operator corresponds to the token HATE_AFTER_AND.


SYNONYM
~~~~~~~~
If ``FLAG_SYNONYM`` is enabled then "``~``" after a whitespace, +, -, or an open bracket corresponds to the token SYNONYM
but with the following conditions:

 - It is ignored if not followed by a word character.
    E.g. Consider the database in ehich we have specified "``happy``" and "``cheerful``" as synonyms.

    Then the query "``~happy``" will return the Query object "``happy@1 SYNONYM cheerful@1``" since here the token SYNONYM
    has been detected.

    But the query "``~ happy``" returns the Query object "``happy@1``" since here the "-" is followed by a whitespace and
    thus not detected as a SYNONYM token.
 - Ignored if present at the end of the query.


*Example query which involve SYNONYM token*

**NOTE**: we must call `set_database()
<http://xapian.org/docs/sourcedoc/html/classXapian_1_1QueryParser.html#010f2b63522f063aa3b5f5645479d9e9>`_ for this to
work. Also we need to add the synonyms to the document. This can be done as follow::

    Xapian::WritableDatabase db(@param);
    db.add_synonym("happy", "cheerful");
    Xapian::QueryParser qp;
    qp.set_database(db);

Now if we give a query "``~happy``" then the Query object returned is "``happy@1 SYNONYM cheerful@1``". 


Details of Xapian::Query::OP_SYNONYM
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Treats a set of queries as synonyms. It is identical to OP_OR except for the weightings returned.

Which Documents are Passed? : 
 Passes documents that match at least one of the queries.
How is the Weight of Documents Adjusted?
 Documents are weighted as if all the sub-queries are are instances of the same term, so multiple matching terms increase
 the wdf value used, and the term frequency is based on the number of documents which will match an OR of all the subqueries.


TERM
~~~~~
TERM is a query term, including prefix (if any).

GROUP_TERM
~~~~~~~~~~~
GROUP_TERM is a query term which follows a TERM or another GROUP_TERM and is only separated by whitespace characters.


PHR_TERM
~~~~~~~~~
PHR_TERM is a query term which follows a TERM or another PHR_TERM and is separated only by one or more phrase generator
characters (hyphen and apostrophe are common examples).

Phrase generator characters (tested via `is_phrase_generator()
<http://xapian.org/docs/sourcedoc/html/queryparser__internal_8cc.html#ab60021d249d420797bf71899944a5d3>`_ ) are the characters that generate a phrase search.


Currently Xapian supports the following characters as phrase generator::

    "." , "-" , "/" , ":" , "\\" , "@"

The phrase operator allows for searching for a specific phrase and returns only matches where all terms appear in th document, in the correct order, giving a weight of the sum of each term.

For example : The query object "``a@1 PHRASE 3 b@2 PHRASE 3 c@3``" matches the documents which match A followed by B followed
by C and gives them a weight of A+B+C.


.. _above:

*Examples of phrase search* : 
 
 - The query : "``xapian.org``" ,returns the Query object "``xapian@1 PHRASE 2 org@2``" (since "." is a phrase generator)
 - The query: "``A B C``" , returns the Query object "``a@1 PHRASE 3 b@2 PHRASE 3 c@3``" whereas the query : "``A B C``" , returns the Query object "``a@1 OR b@2 OR c@3``".
 - The query : "``/home/user/xapian/xapian-core``" , returns the Query object "``home@1 PHRASE 5 user@2 PHRASE 5 xapian@3 PHRASE 5 xapian@4 PHRASE 5 core@5``".

Phrase search also plays an important role with the filters.

For Example suppose we add the filter (non-boolean) for field "``title``" by mapping it to prefix "``T``" (by doing
``qp.add_prefix("title","T")``),

Then the query - ``title:"Harry Potter and the Chamber of Secrets"`` , returns the Query object "``Tharry@1 PHRASE 7 Tpotter@2
PHRASE 7 Tand@3 PHRASE 7 Tthe@4 PHRASE 7 Tchamber@5 PHRASE 7 Tof@6 PHRASE 7 Tsecrets``" i.e. the whole title is treated as
a single entity since the words are connected by ``OP_PHRASE`` and also that all words are prefixed by "T".

Whereas the query - ``title:Harry Potter and the Chamber of Secrets`` , returns the Query object "``Tharry@1 OR potter@2
OR and@3 OR the@4 OR chamber@5 OR of@6 OR secrets@7``" i.e. the whole title is not treated as a single entity since the
words are connected by OP_OR and also all words are not prefixed by "T".

**Note**: For the phrase searches, FLAG_PHRASE should be enabled. (By default it is enabled)


Details of Xapian::Query::OP_PHRASE
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Consider A OP_PHRASE B OP_PHRASE C

Which Documents are Passed? : 
 Passes documents that match A followed by B followed by C.
How is the Weight of Documents Adjusted?
 Matched documents are are given a weight of A+B+C.

WILD_TERM
~~~~~~~~~
WILD_TERM is like a TERM, but has a trailing wildcard which needs to be expanded. It is used to match any number of trailing
characters within a term (Right Truncation).

**Note**: Like in the case of synonyms, for the wildcard expansion we must call `set_database()
<http://xapian.org/docs/sourcedoc/html/classXapian_1_1QueryParser.html#010f2b63522f063aa3b5f5645479d9e9>`_. Also the wildcard
expansion works ONLY IF ``FLAG_WILDCARD`` is enabled. (By default, it is not enabled).

You can limit the number of terms a wildcard will expand to by calling `Xapian::QueryParser::set_max_wildcard_expansion()
<http://xapian.org/docs/sourcedoc/html/classXapian_1_1QueryParser.html#8e2bcb09952fbb2b713ef61e8eb6f638>`_.

If a wildcard expands to more terms than that number, an exception will be thrown. The exception may be thrown by the
QueryParser, or later when Enquire handles the query. The default is not to limit the expansion.

*Example of wildcard query* :

Consider our database contains the terms "code" , "coding" , "coded" , "coder" , "codomain" and "codomain_new" .

Then the query "``cod*``" will return the Query object "``code@1 SYNONYM coded@1 SYNONYM coder@1 SYNONYM coding@1 SYNONYM
codomain@1 SYNONYM codomain_new@1``".



PARTIAL_TERM
~~~~~~~~~~~~~
PARTIAL_TERM is like a TERM, but it's at the end of the query string and we're doing "search as you type". It refers to
the final term of a partial match query, with no following characters and is thus treated as a wildcard, thus expands to
something like WILD_TERM.

Partial matching causes the parser to treat the query as a "*partially entered*" search.


This will automatically treat the final word as a wildcard match, unless it is followed by whitespace, to produce more
stable results from interactive searches.

**Note** : ``FLAG_PARTIAL`` should be enables to support the partial term query

*Example of partial term query* :
Consider the same database as used above in wildcard query. Our database contains the terms "code" , "coding" , "coded" ,
"coder" , "codomain" and "codomain_new".

Then the query "``I am a cod``" will treat the last word of the query ("``cod``") as wildcard term and thus return the
following Query object

"``(i@1 OR am@2 OR a@3) OR ((code@4 SYNONYM coded@4 SYNONYM coder@4 SYNONYM coding@4 SYNONYM codomain@4 SYNONYM codomain_new@4)
OR cod@4)``"

    The problem with this kind of search is that the last word in a partially entered query often has no semantic relation to
    the completed word. For example, a search for "``dynamic cat``" would return a quite different set of results to a search
    for "``dynamic categorisation``". This results in the set of results displayed flicking rapidly as each new character is
    entered. A much smoother result can be obtained if the final word is treated as having an implicit terminating wildcard,
    so that it matches all words starting with the entered characters - thus, as each letter is entered, the set of results
    displayed narrows down to the desired subject.

    A similar effect could be obtained simply by enabling the wildcard matching option, and appending a "*" character to
    each query string. However, this would be confused by searches which ended with punctuation or other characters.



BOOLEAN_FILTER
~~~~~~~~~~~~~~~

BOOLEAN_FILTER is a query term with a prefix registered using `add_boolean_prefix()
<http://xapian.org/docs/sourcedoc/html/classXapian_1_1QueryParser.html#411cc8253c599b7d877749b8e814ee76>`_ .

It's added to the query using an OP_FILTER operator,(or OP_AND_NOT if it's negated) for example, ``site:xapian.org`` or
``-site:xapian.org``.

For example, Suppose in our database, we make the field "``site``" a Boolean filter::

    qp.add_boolean_prefix("site","S")

Now consider the following query::

    watches site:google

The above query will return the following Query object::

    watches@1 FILTER Sgoogle

The corresponding search will return all the documents from site google ONLY (and not any other site since we made "site"
a boolean filter) which have the term "watches" in it.

The operator ``OP_FILTER`` (corresponding to FILTER ) is used (and not OP_OR) since the type of prefix is BOOLEAN_EXCLUSIVE.

If there are boolean filters for different prefixes, they will be combined with the @c Xapian::Query::OP_AND operator.

For example, Consider the same database with the fields "site" and "description".

Let us make both of these boolean filters with DIFFERENT prefixes::

    qp.add_boolean_prefix("site","S");
    qp.add_boolean_prefix("title","T");

Now consider the following query::

    watches site:google title:sale

The above query will return the following Query object::

    watches@1 FILTER (Sgoogle AND Tsale).

If multiple boolean filters are specified in a query for the same prefix, they will be combined with the Xapian::Query::OP_OR
operator.

For example, Consider the same database with the fields "``site``" and "``description``".

Let us make both of these boolean filters with SAME prefixes::

    qp.add_boolean_prefix("site","S");
    qp.add_boolean_prefix("title","S");

Now consider the following query::

    watches site:google title:sale

The above query will return the following Query object::

    watches@1 FILTER (Sgoogle OR Ssale)

It is also possible to make multiple boolean filters specified for SAME prefixes to be combined with OP_AND (and not with
OP_OR as is in the case above).

This corresponds to the case where the document can have multiple terms with this prefix, so multiple filters should be
combined with OP_AND, like happens with filters with different prefixes.

For example, Consider the same database with the fields "site" and "description".

Let us make both of these boolean filters with SAME prefixes::

    qp.add_boolean_prefix("site","S");
    qp.add_boolean_prefix("title","S",false);

Now consider the following query::

    watches site:google title:sale

The above query will return the following Query object::

    watches@1 FILTER (Sgoogle AND Ssale)


RANGE
~~~~~
This token corresponds to a Range search.

The QueryParser supports range searches on document values, matching documents which have values within a given range. There
are several types of range processors available.

To use a range, additional programming is required to tell the QueryParser what format a range is specified in and which
value is to be searched for matches within that range. This then gives rise to the ability to specify ranges as:

$10..50 5..10kg 01/01/1970..01/03/1970 size:3..7

When date ranges are configured (as a DateValueRangeProcessor), you can configure which format dates are to be interpreted as
(i.e. month-day-year) or otherwise.


QUOTE
~~~~~~
Characters ' ``"`` ' , left curly double quote(0x201c) and the right curly double quote(0x201d) match to the token QUOTE.

An unmatched " at the end of the query is ignored to avoid generating an empty pair of QUOTEs which will cause a parse error.

The grammar rule corresponding to the phrased searched is : **QUOTE phrase(P) QUOTE**. Examples of phrased search were
given above_ .


BRA
~~~~
Character '``(``' after a whitespace, bracket , '+' or '-' matches to the token BRA with the following conditions:

 - It is ignored if present at the end of the query.
 - It is ignored if the case corresponds to empty ().

The grammar rule corresponding to the bracketed expression is : **compound_term ::= BRA expr KET**


KET
~~~~
Character '``)``' represents the token KET. It represents the end of a bracketed expression.

The grammar rule corresponding to the bracketed expression is : **compound_term ::= BRA expr KET**

CJKTERM
~~~~~~~~
It corresponds to the case if CJK n-gram code is being used i.e. if `CJK::is_cjk_enabled()
<http://xapian.org/docs/sourcedoc/html/namespaceCJK.html#6d76ede0fd2a9ad3a12532d63c05caee>`_ is true and
`CJK::codepoint_is_cjk(*itertor) <http://xapian.org/docs/sourcedoc/html/namespaceCJK.html#efab5934f6a82a989b994fad5068670d>`_
returns true.


EMPTY_GROUP_OK
~~~~~~~~~~~~~~~
This token corresponds to the end of a `group`_ (a non-terminal, explained later), where group refers to a group of terms
separated only by whitespace - candidates for multi-term synonyms

The corresponding grammar rule is : **group ::= group EMPTY_GROUP_OK**




NON-TERMINALS
--------------

The QueryParser grammar has the following 14 NON-TERMINALS (as mentioned earlier, in Lemon, non-terminals can have different
type/value):


query
~~~~~~

The whole query - just an expr or nothing.


expr
~~~~~ 

expr - A query expression.



bool_arg
~~~~~~~~~

bool_arg - an argument to a boolean operator such as AND or OR.


prob_expr
~~~~~~~~~~

prob_expr - a single compound term, or a prob.


prob
~~~~~

prob - a probabilistic sub-expression consisting of stop_terms, "+" terms, "-" terms, boolean filters, and/or value ranges.


stop_prob
~~~~~~~~~~

stop_prob - A prob or a stop_term.



stop_term
~~~~~~~~~~~

stop_term - A term which should be checked against the stopword list, or a compound_term.

If a term is loved, hated, or in a phrase, we don't want to consult the stopword list, so stop_term isn't used there
(instead term is).




term 
~~~~~

It is different from stop_term in the sense that here we don't consult the stopword list. 

This corresponds to the case if the term is loved, hated, or in a phrase.



compound_term
~~~~~~~~~~~~~~

compound_term - A WILD_TERM, a quoted phrase (with or without prefix), a phrased_term, group, near_expr, adj_expr, or a
bracketed subexpression (with or without prefix).


phrase
~~~~~~~

phrase - The "inside the quotes" part of a double-quoted phrase.

  
phrased_term
~~~~~~~~~~~~~

A phrased term works like a single term, but is actually 2 or more terms linked together into a phrase by punctuation. There
must be at least 2 terms in order to be able to have punctuation between the terms.


group
~~~~~~

group - A group of terms separated only by whitespace - candidates for multi-term synonyms.


near_expr
~~~~~~~~~~

near_expr - 2 or more terms with NEAR in between. There must be at least 2 terms in order for there to be any NEAR operators.


adj_expr
~~~~~~~~~

adj_expr - 2 or more terms with ADJ in between. There must be at least 2 terms in order for there to be any ADJ operators. 


Grammar Rules
--------------

Following are the grammar rules of QueryParser , listed together in the order::

	0.  query ::= expr.

	1.  query ::= .

	2.  expr ::= prob_expr.

	3.  expr ::= bool_arg AND bool_arg.

	4.  expr ::= bool_arg NOT bool_arg.

	5.  expr ::= bool_arg AND NOT bool_arg.

	6.  expr ::= bool_arg AND HATE_AFTER_AND bool_arg.

	7.  expr ::= bool_arg OR bool_arg.

	8.  expr ::= bool_arg XOR bool_arg.

	9.  bool_arg ::= expr.

	10. bool_arg ::= . 

	11. prob_expr ::= prob.

	12. prob_expr ::= term.

	13. prob ::= RANGE.

	14. prob ::= stop_prob RANGE.

	15. prob ::= stop_term stop_term.

	16. prob ::= prob stop_term.

	17. prob ::= LOVE term.

	18. prob ::= stop_prob LOVE term.

	19. prob ::= HATE term.

	20. prob ::= stop_prob HATE term.

	21. prob ::= HATE BOOLEAN_FILTER.

	22. prob ::= stop_prob HATE BOOLEAN_FILTER.

	23. prob ::= BOOLEAN_FILTER.

	24. prob ::= stop_prob BOOLEAN_FILTER.

	25. prob ::= LOVE BOOLEAN_FILTER.

	26. prob ::= stop_prob LOVE BOOLEAN_FILTER.

	27. stop_prob ::= prob.

	28. stop_prob ::= stop_term.

	29. stop_term ::= TERM.

	30. stop_term ::= compound_term.

	31. term ::= TERM.

	32. term ::= compound_term.

	33. compound_term ::= WILD_TERM.

	34. compound_term ::= PARTIAL_TERM.

	35. compound_term ::= QUOTE phrase QUOTE.

	36. compound_term ::= phrased_term.

	37. compound_term ::= group.

	38. compound_term ::= near_expr.

	39. compound_term ::= adj_expr.

	40. compound_term ::= BRA expr KET.

	41. compound_term ::= SYNONYM TERM.

	42. compound_term ::= CJKTERM.

	43. phrase ::= TERM.

	44. phrase ::= CJKTERM.

	45. phrase ::= phrase TERM.

	46. phrase ::= phrase CJKTERM.

	47. phrased_term ::= TERM PHR_TERM.

	48. phrased_term ::= phrased_term PHR_TERM.

	49. group ::= TERM GROUP_TERM.

	50. group ::= group GROUP_TERM.

	51. group ::= group EMPTY_GROUP_OK.

	52. near_expr ::= TERM NEAR TERM.

	53. near_expr ::= near_expr NEAR TERM.

	54. adj_expr ::= TERM ADJ TERM.

	55. adj_expr ::= adj_expr ADJ TERM.


The Lexer
==========

QueryParser has a self written lexer which iterates through the input query, determines the Tokens and calls the parser
[ via `static void Parse( yyParser * , int, Term * , State * )`_ ) each time a new Token is determined, along with the
information of that Token.

The lexer uses the enum mode to keep track of the present state and the information of the past Token(s).::

    enum {
	DEFAULT, IN_QUOTES, IN_PREFIXED_QUOTES, IN_PHRASED_TERM, IN_GROUP,
	IN_GROUP2, EXPLICIT_SYNONYM
    } mode = DEFAULT;

The default value of mode is DEFAULT.

Following is the information regarding each of them :


DEFAULT
--------
This is the default value of mode.

IN_QUOTES
----------
If ' ``"`` ' character detected along with the conditions that are required for Quotes (as mentioned above in `QUOTE`_ ),
then the mode is set to this one and parser is called with parameters as::


     Parse(pParser, QUOTE, NULL, &state);


IN_PREFIXED_QUOTES
-------------------
Same as `IN_QUOTES`_, and the Parse is called with same parameters.

The only difference is that it corresponds to a case like 

    subject:"space flight"

where "``subject``" corresponds to a filter.


IN_PHRASED_TERM
----------------
The character is tested for phrase generator (as mentioned above in `PHR_TERM`_ ), and if it is, then the mode is set to
this one and the parser is called with the parameters as::

    Parse(pParser, PHR_TERM, term_obj, &state);


IN_GROUP
---------
If the we have a term, and we detect another term such that they are separated only via whitespace (as mentioned above in
`group`_), then this mode is set.


IN_GROUP2
-----------
This is same as `IN_GROUP`_ with the difference that this corresponds to the case when we have more than two terms separated
via whitespace.



EXPLICIT_SYNONM
-----------------
If ' ``~`` ' character is detected along with the conditions that are required for Synonyms (as described above in `SYNONYM`_),
then the mode is set to this one and the parser is called with parameters as::


    Parse(pParser, SYNONYM, NULL, &state);
    
    
Functioning of Parser, The Parse Tree
=======================================

Following examples describe the functioning of the parser, the overall view as to how are the tokens generated and how are
they processed and parsed.

The bottom up parse tree corresponding to the QueryParser LR(1) grammar are shown and described.

[ Unless mentioned explicitly, the Query objects correspond to the default stemming option ( STEM_SOME, and hence the 'Z'
prefix in some of them ) ]


A Simple Query
---------------

Consider the following query::

	latest new watches

Here the tokens generated by the lexer are : TERM("latest"), GROUP_TERM("new") and GROUP_TERM("watches")

The parser then reduces the tokens in a bottom-up manner as follow::

                            
                      query		Level-7
                        |
                       expr		Level-6
                        |
                      prob_expr		Level-5
                        |
                       term		Level-4
                        |
                    compound_term	Level-3
                        |
                      group		Level-2
                      /   \
                     /     \ 
                  group     \		Level-1
                  /  \       \
                 /    \       \
                /      \       \           
             TERM  GROUP_TERM  GROUP_TERM
               |        |       |
             "latest"  "new"  "watches"

The corresponding grammar rules applied in the order of application are as follow::

	Level 1 - group ::= TERM GROUP_TERM.
	Level 2 - group ::= group GROUP_TERM.
	Level 3 - compound_term ::= group.
	Level 4 - term ::= compound_term.
	Level 5 - prob_expr ::= term.
	Level 6 - expr ::= prob_expr.
	Level 7 - query ::= expr. 

In this case, the Query object formed is::
	
	Query((Zlatest@1 OR Znew@2 OR Zwatch@3))

Boolean Query
--------------

Consider the following query::

	xapian OR google

Here the tokens generated by the lexer are : TERM("xapian"), OR and TERM("google")

The parser then reduces the tokens in a bottom-up manner as follow::  

                      query		Level-6
                        |
                      expr		Level-5 
                      / |  \
                     /  |   \ 
                    /   |    \
              bool_arg  |   bool_arg	Level-4
                 |      |      |
                expr    |     expr	Level-3
                 |      |      |
            prob_expr   |    prob_expr	Level-2 
                 |      |      |
               term     |     term	Level-1
                 |      |      |
               TERM    OR     TERM
                 |      |      |
             "xapian" "OR"  "google" 
           

The corresponding grammar rules applied in the order of application are as follow::

	Level 1 - term ::= TERM.             term ::= TERM.
	Level 2 - prob_expr ::= term.        prob_expr ::= term.
	Level 3 - expr ::= prob_expr.        expr ::= prob_expr.
	Level 4 - bool_arg ::= expr.         bool_arg ::= expr.
	Level 5 - expr ::= bool_arg OR bool_arg.
	Level 6 - query ::= expr.   

In this case, the Query object formed is::
	
	Query((Zxapian@1 OR Zgoogl@2))

Similarly, other boolean operators like AND, XOR etc. can be used.


Near Query
------------

Consider the following query::

	tower NEAR libery NEAR ohio

Here the tokens generated by the lexer are : TERM("tower"), NEAR(10), TERM("liberty"), NEAR(10) and TERM("ohio")

The parser then reduces the tokens in a bottom-up manner as follow:: 
                            
                                     query		Level-7
                                       |
                                      expr		Level-6
                                       |
                                   prob_expr		Level-5
                                       |
                                     term		Level-4
                                       |
                                compound_term		Level-3
                                       |
                                    near_expr		Level-2 
                                    /     | \
                                   /      |  \   
                                  /       |   \ 
                                 /        |    \ 
                                /         |     \
                               /          |      \           
                              /           |       \
                             /            |        \ 
                      near_expr           |         \  	Level-1
                     /    |  \            |          \   
                    /     |   \           |           \  
                   /      |    \          |            \
               TERM  NEAR(10)  TERM     NEAR(10)     TERM
               |       |         |        |            |
            "tower"  "NEAR"   "liberty"  "NEAR"      "ohio"

The corresponding grammar rules applied in the order of application are as follow::
	
	Level 1 - near_expr ::= TERM NEAR TERM.
	Level 2 - near_expr ::= near_expr NEAR TERM.
	Level 3 - compound_term ::= near_expr.
	Level 4 - term ::= compound_term.
	Level 5 - prob_expr ::= term.
	Level 6 - expr ::= prob_expr.
	Level 7 - query ::= expr.

In this case, the Query object formed is::
	
	Query((tower@1 NEAR 12 libery@2 NEAR 12 ohio@3))

Phrased Query
---------------

Consider the following query::

	anonymous@xapian.org

Here ' @ ' and ' . ' are the phrase generator characters. (Described above)

Here the tokens generated by the lexer are : TERM("anonymous"), PHR_TERM("xapian"), PHR_TERM("org").

The parser then reduces the tokens in a bottom-up manner as follow:: 


                      query		Level-7
                        |
                       expr		Level-6
                        |
                      prob_expr		Level-5
                        |
                      term		Level-4 
                        |
                    compound_term	Level-3
                        |
                   phrased_term		Level-2
                      /   \
                     /     \ 
             phrased_term   \		Level-1	
                  /  \       \
                 /    \       \
                /      \       \           
             TERM   PHR_TERM  PHR_TERM
               |        |       |
       "anonymous"  "xapian"  "org"


The corresponding grammar rules applied in the order of application are as follow::

	Level 1 - phrased_term ::= TERM PHR_TERM.
	Level 2 - phrased_term ::= phrased_term PHR_TERM.
	Level 3 - compound_term ::= phrased_term.
	Level 4 - term ::= compound_term.
	Level 5 - prob_expr ::= term.
	Level 6 - expr ::= prob_expr.
	Level 7 - query ::= expr. 

In this case, the Query object formed is::
	
	Query((anonymous@1 PHRASE 3 xapian@2 PHRASE 3 org@3))

Boolean Operator and NEAR operator
-----------------------------------

Consider the following query::

	a AND b NEAR c

Here the tokens generated by the lexer are : TERM("a"), AND, TERM("b"), NEAR(10), TERM("c").

This example shows the effect of precedence of NEAR being Higher than that of boolean operators.

The parser then reduces the tokens in a bottom-up manner as follow:: 
                                 
                                 
                         query 				Level-8
                           | 
                          expr				Level-7
                        / |    \
                       /  |     \          
                      /   |      \        
                     /    |      bool_arg  		Level-6 
                    /     |           |
                   /      |           |      
                  /       |          expr		Level-5
                 /        |           |
            bool_arg      |         prob_expr		Level-4 
                |         |           | 
             expr         |           term   		Level-3
                |         |           |
           prob_expr      |          compound_term  	Level-2
                |         |                  | 
              term        |                near_expr	Level-1    
                |         |                /    |   \
                |         |               /     |    \
              TERM       AND         TERM  NEAR(10)  TERM
               |          |            |      |       |
              "a"       "AND"        "b"    NEAR     "c"


The corresponding grammar rules applied in the order of application are as follow::

	Level 1 - term ::= TERM.		near_expr ::= TERM NEAR TERM.
	Level 2 - prob_expr ::= term.		compound_term ::= near_expr.
	Level 3 - expr ::= prob_expr.		term ::= compound_term.
	Level 4 - bool_arg ::= expr.		prob_expr ::= term.
	Level 5 - expr ::= prob_expr.
	Level 6 - bool_arg ::= expr.
	Level 7 - expr ::= bool_arg AND bool_arg.
	Level 8 - query ::= expr.

In this case, the Query object formed is::
	
	Query((Za@1 AND (b@2 NEAR 11 c@3)))


//Please check that the parse tree of this is correct. Not sure about this one.

Bracketed Query and Failure of NEAR query
-------------------------------------------

Consider the following query::

	(x OR y) NEAR z

Here the tokens generated by the lexer are : BRA, TERM("x"), OR, TERM("y"), KET, TERM("near"), GROUP_TERM("z").

In this example "NEAR" does not generate a NEAR query, since the boolean query in the expressions reduces to 'expr' and
there is no grammar rule at present that supports the NEAR query with bracketed expressions.


The parser then reduces the tokens in a bottom-up manner as follow::                     
				     
				                     query					Level-11
				                       | 
				                      expr					Level-10
				                       |  
				                    prob_expr  					Level-9
				                       |
				                      prob					Level-8
				                    /      \
				                   /        \
				                  /          \
				                 /            \
				                /              \
				             stop_term          \				Level-7
				                |                \  
				         compund_term             \				Level-6
				       /        |    \             \
				      /         |     \             \
			             /         expr    \             \				Level-5
				    /         / |  \    \             \
				   /         /  |   \    \             \
				  /         /   |    \    \             \
	             		 /    bool_arg  | bool_arg \            stop_term		Level-4
				/        |      |      |    \                |
			       /        expr    |     expr   \          compound_term  		Level-3
		              /		 |      |      |      \                  |  
		  	     /       prob_expr  |   prob_expr  \               group		Level-2
			    /	         |      |      |        \              /    \ 
			   /           term     |     term       \            /      \		Level-1
			  /	         |      |      |          \          /        \
			BRA            TERM     OR     TERM       KET      TERM    GROUP_TERM
			 |	         |      |      |           |         |        | 
			'('             "x"    "OR"   "y"         ')'      "near"    "z" 

The corresponding grammar rules applied in the order of application are as follow::

	Level 1 - term ::= TERM.			term ::= TERM.
	Level 2 - prob_expr ::= term.			prob_expr ::= term.		group ::= TERM GROUP_TERM.
	Level 3 - expr ::= prob_expr.			expr ::= prob_expr.		compound_term ::= group.
	Level 4 - bool_arg ::= expr.			bool_arg ::= expr.		stop_term ::= compound_term.
	Level 5 - expr ::= bool_arg OR bool_arg.	
	Level 6 - compound_term ::= BRA expr KET.
	Level 7 - stop_term ::= compound_term.
	Level 8 - prob ::= stop_term stop_term.
	Level 9 - prob_expr ::= prob.
	Level 10 -expr ::= prob_expr. 
	Level 11 - query ::= expr.

In this case, the Query object formed is::
	
	Query(((Zx@1 OR y@3) OR (near@4 OR Zz@5)))

Wildcard Query
---------------

FLAG_WILDCARD should be enabled to support the Wildcard query.

Suppose our database contains the terms "code" , "coding" , "coded" , "coder" , "codomain" and "codomain_new" .

Consider the following query::

	cod*

Here the token generated by the lexer is : WILD_TERM("cod")

The parser then reduces the tokens in a bottom-up manner as follow:: 

                            
                query		Level-5
                  |
                 expr		Level-4
                  |
               prob_expr	Level-3	
                  |
                term		Level-2
                  |
             compound_term	Level-1
                  |
               WILD_TERM	
  		  |
	        "cod*"
 
The corresponding grammar rules applied in the order of application are as follow::

	Level 1 - compound_term ::= WILD_TERM.
	Level 2 - term ::= compound_term.
	Level 3 - prob_expr ::= term.
	Level 4 - expr ::= prob_expr.
	Level 5 - query ::= expr.

In this case, the Query object formed is::
	
	Query((code@1 SYNONYM coded@1 SYNONYM coder@1 SYNONYM coding@1 SYNONYM codomain@1 SYNONYM codomain_new@1))

Partial Query 
--------------

FLAG_PARTIAL should be enabled to support the partial term query.

Suppose our database contains the terms "code" , "coding" , "coded" , "coder" , "codomain" and "codomain_new".

Consider the following query::

	I am a cod

Here the tokens generated by the lexer is : TERM("i"), GROUP_TERM("am"), GROUP_TERM("a"), PARTIAL_TERM("cod") 

The parser then reduces the tokens in a bottom-up manner as follow:: 
				      
				      query			Level-9
					|
				      expr			Level-8
					|		
				    prob_expr			Level-7
					|
				       prob			Level-6
	                               /  \
                                      /    \
	                      stop_term     \			Level-5
                               |             \
	                   compound_term      \			Level-4
                               |               \
	                     group              \ 		Level-3
                             /   \               \
                            /     \               \   
	                 group     \              stop_term	Level-2
                         /  \       \                |
                        /    \       \          compound_term	Level-1
                       /      \       \              |
                    TERM  GROUP_TERM  GROUP_TERM   PARTIAL_TERM
                      |        |       |             |
                    "i"       "am"    "a"          "cod"

The corresponding grammar rules applied in the order of application are as follow::

	Level 1 - compound_term ::= PARTIAL_TERM.
	Level 2 - group ::= TERM GROUP_TERM.		stop_term ::= compound_term.
	Level 3 - group ::= group GROUP_TERM.
	Level 4 - compound_term ::= group.
	Level 5 - stop_term ::= compound_term.
	Level 6 - prob ::= stop_term stop_term.
	Level 7 - prob_expr ::= prob.
	Level 8 - expr ::= prob_expr.
	Level 9 - query ::= expr. 

In this case, the Query object formed (according to the database mentioned above) is::
	
	Query(((Zi@1 OR Zam@2 OR Za@3) OR ((code@4 SYNONYM coded@4 SYNONYM coder@4 SYNONYM coding@4 SYNONYM codomain@4 SYNONYM codomain_new@4) OR Zcod@4)))
  

Multiple Filters
-----------------

Suppose our database has the fields "site" and "description" and are prefixed to "S" and "T" respectively::
	
	qp.add_boolean_prefix("site","S");
	qp.add_boolean_prefix("title","T");
 
Consider the following query::

	watches title:sale site:google

Here the tokens generated by the lexer are : TERM("watches"), BOOLEAN_FILTER("title:sale"), BOOLEAN_FILTER("site:google") 

The parser then reduces the tokens in a bottom-up manner as follow::                             
                     
                        
                      query                         Level-8
                        |
                       expr                         Level-7
                        |
		     prob_expr		            Level-6
			|
		       prob			    Level-5	
		     /	    \
                    /        \
              stop_prob       \                     Level-4
		|   	       \ 	
	      prob		\		    Level-3	
	     /	  \		 \
       stop_prob   \		  \		    Level-2
	   |        \		   \   
	stop_term    \		    \  		    Level-1
           |          \              \		  
	 TERM     BOOLEAN_FILTER   BOOLEAN_FILTER   
	   |                |               |	
	"watches"	"title:sale"	"site:google"

The corresponding grammar rules applied in the order of application are as follow::

	Level 1 - stop_term ::= TERM.
	Level 2 - stop_prob ::= stop_term.
	Level 3 - prob ::= stop_prob BOOLEAN_FILTER
	Level 4 - stop_prob ::= prob.
	Level 5 - prob ::= stop_prob BOOLEAN_FILTER
	Level 6 - prob_expr ::= prob.
	Level 7 - expr ::= prob_expr.
	Level 8 - query ::= expr. 

In this case, the Query object formed (according to the database mentioned above) is::
	
	Query((Zwatch@1 FILTER (Sgoogle AND Tsale)))

LOVE
------

Consider the following query::

	xapian +strategy

Here the tokens generated by the lexer are : TERM("xapian"), LOVE, TERM("strategy") 

The parser then reduces the tokens in a bottom-up manner as follow::                             
                     
                        
	                     query		Level-6
                               |
	                      expr		Level-5
			       |
			    prob_expr		Level-4
			       |
                              prob		Level-3
                             / |  \
                            /  |   \ 
	            stop_prob  |    \		Level-2
                        |      |     \ 
	           stop_term   |    term	Level-1
                        |      |      |
                      TERM    LOVE   TERM
                        |      |      |
                    "xapian"  "+"  "strategy" 
           

The corresponding grammar rules applied in the order of application are as follow::

	Level 1 - stop_term ::= TERM.             	term ::= TERM.
	Level 2 - stop_prob ::= stop_term.
	Level 3 - prob ::= stop_prob LOVE term.
	Level 4 - prob_expr ::= prob.
	Level 5 - expr ::= prob_expr.
	Level 6 - query ::= expr.   

In this case, the Query object formed is::
	
	Query((Zstrategi@2 AND_MAYBE Zxapian@1))

Similarly, the HATE query ("like xapian -strategy") is parsed.



An Ineffective Query
----------------------

Consider the following query::

	a OR b -c

Here the expected behaviour should be (a OR b) -c, BUT the present grammar parses it as a OR ( b -c )

This is a present bug ( `ticket #521 <http://trac.xapian.org/ticket/521>`_ )

Here the tokens generated by the lexer are : TERM("a"), OR, TERM("b"), HATE, TERM("c") 

The parser then reduces the tokens in a bottom-up manner as follow::                             
                      
                               query				Level-8
                                |
                               expr				Level-7
                              /|   \
                     	     / |    \ 
			    /  |     \		                     
			   /   |      bool_arg			Level-6
		          /    |          |
			 /     |         expr			Level-5
			/      |	    |
		   bool_arg    |	  prob_expr		Level-4
		       |       |	      |
		     expr      |             prob		Level-3
		       |       |            / |  \
		       |       |           /  |   \ 
		     prob_expr |  stop_prob   |    \		Level-2
		       |       |      |       |     \
		     term      |   stop_term  |    term		Level-1
		       |       |      |       |      |
		     TERM      OR    TERM   HATE   TERM
		       |       |      |      |      |
	              "a"     "OR"   "b"    "-"    "c"                         

The corresponding grammar rules applied in the order of application are as follow::

	Level 1 - term ::= TERM.			stop_term ::= TERM.			term ::= TERM.
	Level 2 - prob_expr ::= term.			stop_prob ::= stop_term.
	Level 3 - expr ::= prob_expr.			prob ::= stop_prob HATE term.
	Level 4 - bool_arg ::= expr.			prob_expr ::= prob.
	Level 5 - expr ::= prob_expr.
	Level 6 - bool_arg ::= expr.
	Level 7 - expr ::= bool_arg OR bool_arg.
	Level 8 - query ::= expr.  

In this case, the Query object formed is::
	
	Query((Za@1 OR (Zb@2 AND_NOT Zc@3)))
	

	


